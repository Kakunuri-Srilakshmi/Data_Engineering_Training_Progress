{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " # 📝 What is PySpark?\n",
        "\n",
        "What is PySpark?\n",
        "\n",
        "- Python library for Apache Spark.\n",
        "- Used for big data processing and analytics.\n",
        "- Works with large datasets using DataFrames.\n",
        "- Allows operations like:\n",
        "   - Filter rows\n",
        "   - Group data\n",
        "   - Join tables\n",
        "   - Aggregate data efficiently"
      ],
      "metadata": {
        "id": "HBAzR7JZyTIL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVJVOCNtvnHR",
        "outputId": "9f029300-3ff9-45db-d71f-6ab0365c016d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "#create Spark Session\n",
        "spark = SparkSession.builder.appName(\"Sri\").getOrCreate()\n",
        "\n",
        "# check spark version\n",
        "print(\"Apache Spark version:\", spark.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEBjV1-nvvhp",
        "outputId": "c51b1f3d-d9f2-495f-9faf-4630fb9af2e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apache Spark version: 3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Creating a DataFrame"
      ],
      "metadata": {
        "id": "QWlDhsplzST0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample data\n",
        "data = [(\"Rahul\", 21), (\"Priya\", 22), (\"Sri\", 21)]\n",
        "\n",
        "#define schema (columns)\n",
        "columns = [\"Name\", \"Age\"]\n",
        "\n",
        "#create DataFrame\n",
        "df = spark.createDataFrame(data, columns)\n",
        "\n",
        "#show DataFrame\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDbzS2sMv15r",
        "outputId": "4fdc22df-a4ce-4781-a8ae-92a76eb96436"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---+\n",
            "| Name|Age|\n",
            "+-----+---+\n",
            "|Rahul| 21|\n",
            "|Priya| 22|\n",
            "|  Sri| 21|\n",
            "+-----+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " # DataFrame Operations"
      ],
      "metadata": {
        "id": "GUDyiSklzGcF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select column\n",
        "df.select(\"Name\").show()           # df -> data frame\n",
        "\n",
        "#filter rows\n",
        "df.filter(df[\"Age\"] > 21).show()\n",
        "\n",
        "#count rows\n",
        "print(\"Total rows:\", df.count())\n",
        "\n",
        "# group by column\n",
        "df.groupBy(\"Age\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67VpN0zov7X3",
        "outputId": "017facf6-9e6e-4245-d661-bdda46d94dc1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "| Name|\n",
            "+-----+\n",
            "|Rahul|\n",
            "|Priya|\n",
            "|  Sri|\n",
            "+-----+\n",
            "\n",
            "+-----+---+\n",
            "| Name|Age|\n",
            "+-----+---+\n",
            "|Priya| 22|\n",
            "+-----+---+\n",
            "\n",
            "Total rows: 3\n",
            "+---+-----+\n",
            "|Age|count|\n",
            "+---+-----+\n",
            "| 21|    2|\n",
            "| 22|    1|\n",
            "+---+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading CSV Data in Python\n",
        "\n",
        "- csv_data → CSV content stored as a string.\n",
        "- StringIO → Treats the string as a file so Python can read it like a CSV file.\n",
        "- DictReader → Reads CSV rows as dictionaries with column names as keys."
      ],
      "metadata": {
        "id": "kGVD1eI3zoqi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTPIUVOtB4Vb",
        "outputId": "b6688787-f227-433b-a223-7ae1419b6a00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 - Rahul Sharma (IT) -> rs.55000\n",
            "2 - Priya Singh (HR) -> rs.60000\n",
            "3 - Aman Kumar (Finance) -> rs.48000\n",
            "4 - Sneha Reddy (Marketing) -> rs.52000\n",
            "5 - Arjun Mehta (IT) -> rs.75000\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import io\n",
        "\n",
        "# Step 1: Create CSV data as a string\n",
        "csv_data = \"\"\"id,name,department,salary\n",
        "1,Rahul Sharma,IT,55000\n",
        "2,Priya Singh,HR,60000\n",
        "3,Aman Kumar,Finance,48000\n",
        "4,Sneha Reddy,Marketing,52000\n",
        "5,Arjun Mehta,IT,75000\n",
        "\"\"\"\n",
        "\n",
        "#step 2: use stringIO to treat string like a file\n",
        "file_like = io.StringIO(csv_data)\n",
        "\n",
        "# step 3: Read CSV using DictReader\n",
        "reader = csv.DictReader(file_like)\n",
        "\n",
        "# Step 4: Iterate through the rows and print them\n",
        "for row in reader:\n",
        "    print(f\"{row['id']} - {row['name']} ({row['department']}) -> rs.{row['salary']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading JSON Data in Python\n",
        "\n",
        "- json_data → JSON content stored as a string.\n",
        "- json.loads() → Converts JSON string into a Python list of dictionaries.\n",
        "- Iteration → Prints each record in a readable format."
      ],
      "metadata": {
        "id": "U2ruwx3Rz3Qe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "#step 1 : create json as a string\n",
        "json_data = '''\n",
        "[\n",
        "  { \"id\": 1, \"name\": \"Rahul Sharma\", \"age\": 21, \"city\": \"Bangalore\" },\n",
        "  { \"id\": 2, \"name\": \"Priya Singh\", \"age\": 22, \"city\": \"Delhi\" },\n",
        "  { \"id\": 3, \"name\": \"Aman Kumar\", \"age\": 20, \"city\": \"Hyderabad\" }\n",
        "]\n",
        "'''\n",
        "\n",
        "#step 2 : parse json string + python list of dictionaries\n",
        "students = json.loads(json_data)\n",
        "\n",
        "#step 3: process the data\n",
        "print(\"Student Records:\")\n",
        "for s in students:\n",
        "    print(f\"{s['id']} - {s['name']} ({s['city']}) -> Age {s['age']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E79v8xOyDbrv",
        "outputId": "2260839f-cc23-408b-fa2b-353ce3fb0875"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Student Records:\n",
            "1 - Rahul Sharma (Bangalore) -> Age 21\n",
            "2 - Priya Singh (Delhi) -> Age 22\n",
            "3 - Aman Kumar (Hyderabad) -> Age 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Updating JSON Data in Python"
      ],
      "metadata": {
        "id": "-wSvmNlK0hqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# step 1 : json data in memory\n",
        "json_data = '''\n",
        "[\n",
        "  { \"id\": 1, \"name\": \"Rahul Sharma\", \"age\": 21, \"city\": \"Bangalore\" },\n",
        "  { \"id\": 2, \"name\": \"Priya Singh\", \"age\": 22, \"city\": \"Delhi\" }\n",
        "]\n",
        "'''\n",
        "\n",
        "# step2: load json into python list\n",
        "students = json.loads(json_data)\n",
        "\n",
        "# step 3: Add a new student\n",
        "new_student = {\n",
        "    \"id\": 3,\n",
        "    \"name\": \"Aman Kumar\",\n",
        "    \"age\": 20,\n",
        "    \"city\": \"Hyderabad\"\n",
        "}\n",
        "\n",
        "students.append(new_student)\n",
        "\n",
        "# step 4: update an existing student\n",
        "for s in students:\n",
        "  if s[\"id\"] == 1:\n",
        "      s[\"city\"] = \"pune\"\n",
        "\n",
        "# step 5: convert back to json string\n",
        "updated_json = json.dumps(students, indent=2)\n",
        "\n",
        "# print results\n",
        "print(\"Updated JSON Data:\\n\", updated_json)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nr2mEGq3OTaQ",
        "outputId": "fa825ab4-f7db-444a-dd5a-bfdbd8e3f811"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated JSON Data:\n",
            " [\n",
            "  {\n",
            "    \"id\": 1,\n",
            "    \"name\": \"Rahul Sharma\",\n",
            "    \"age\": 21,\n",
            "    \"city\": \"pune\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": 2,\n",
            "    \"name\": \"Priya Singh\",\n",
            "    \"age\": 22,\n",
            "    \"city\": \"Delhi\"\n",
            "  },\n",
            "  {\n",
            "    \"id\": 3,\n",
            "    \"name\": \"Aman Kumar\",\n",
            "    \"age\": 20,\n",
            "    \"city\": \"Hyderabad\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "#create Spark Session\n",
        "spark = SparkSession.builder.appName(\"Sri\").getOrCreate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCFZgCJWqYBB",
        "outputId": "5b38141f-722f-4015-c9bc-ba70b2858a8d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "\n",
        "csv_data = \"\"\"id,name,department,salary\n",
        "1,Rahul Sharma,IT,55000\n",
        "2,Priya Singh,HR,60000\n",
        "3,Aman Kumar,Finance,48000\n",
        "4,Sneha Reddy,Marketing,52000\n",
        "5,Arjun Mehta,IT,75000\n",
        "6,Divya Nair,Finance,67000\n",
        "\"\"\"\n",
        "\n",
        "with open(\"employees.csv\", \"w\") as f:\n",
        "  f.write(csv_data)"
      ],
      "metadata": {
        "id": "7C2-C4OkWcs1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"employees.csv\", header = True, inferSchema = True)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4sD_pkPp3bk",
        "outputId": "5cbd5b46-f871-4fc3-a735-8fe67443f23c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------+----------+------+\n",
            "| id|        name|department|salary|\n",
            "+---+------------+----------+------+\n",
            "|  1|Rahul Sharma|        IT| 55000|\n",
            "|  2| Priya Singh|        HR| 60000|\n",
            "|  3|  Aman Kumar|   Finance| 48000|\n",
            "|  4| Sneha Reddy| Marketing| 52000|\n",
            "|  5| Arjun Mehta|        IT| 75000|\n",
            "|  6|  Divya Nair|   Finance| 67000|\n",
            "+---+------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformations\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# 📝 Key Points about Transformations\n",
        "\n",
        "* **Lazy Execution**:\n",
        "  Spark doesn’t run transformations right away. Instead, it builds a **logical plan** (a DAG – Directed Acyclic Graph).\n",
        "  The computation only runs when an **action** (like `.show()` or `.count()`) is called.\n",
        "\n",
        "* **Return Type**:\n",
        "  A transformation always returns a **new DataFrame or RDD**. It does **not modify the existing one**.\n",
        "\n",
        "* **Two Types of Transformations**:\n",
        "\n",
        "  1. **Narrow Transformations** → Each input partition contributes to only one output partition.\n",
        "     (e.g., `map()`, `filter()`, `select()`)\n",
        "  2. **Wide Transformations** → Data is shuffled across partitions.\n",
        "     (e.g., `groupBy()`, `join()`)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "AzCIY6cnyK79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select name & salary\n",
        "df.select(\"name\", \"salary\").show()\n",
        "\n",
        "# filter employess with > 60,000\n",
        "df.filter(df[\"salary\"] > 60000).show()\n",
        "\n",
        "# order by salary descending\n",
        "df.orderBy(df[\"salary\"].desc()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FZVJuxUqRHm",
        "outputId": "4ea8cb64-ba2d-4665-cd8a-c356fd8cf604"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------+\n",
            "|        name|salary|\n",
            "+------------+------+\n",
            "|Rahul Sharma| 55000|\n",
            "| Priya Singh| 60000|\n",
            "|  Aman Kumar| 48000|\n",
            "| Sneha Reddy| 52000|\n",
            "| Arjun Mehta| 75000|\n",
            "|  Divya Nair| 67000|\n",
            "+------------+------+\n",
            "\n",
            "+---+-----------+----------+------+\n",
            "| id|       name|department|salary|\n",
            "+---+-----------+----------+------+\n",
            "|  5|Arjun Mehta|        IT| 75000|\n",
            "|  6| Divya Nair|   Finance| 67000|\n",
            "+---+-----------+----------+------+\n",
            "\n",
            "+---+------------+----------+------+\n",
            "| id|        name|department|salary|\n",
            "+---+------------+----------+------+\n",
            "|  5| Arjun Mehta|        IT| 75000|\n",
            "|  6|  Divya Nair|   Finance| 67000|\n",
            "|  2| Priya Singh|        HR| 60000|\n",
            "|  1|Rahul Sharma|        IT| 55000|\n",
            "|  4| Sneha Reddy| Marketing| 52000|\n",
            "|  3|  Aman Kumar|   Finance| 48000|\n",
            "+---+------------+----------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Aggregation\n",
        " 📝 What is Aggregation?\n",
        "\n",
        "* An operation that **groups data** and applies a **summary function** (like sum, avg, count, min, max).\n",
        "* Used to answer questions like:\n",
        "\n",
        "  * *“What is the average salary per department?”*\n",
        "  * *“How many employees are in each department?”*\n",
        "  * *“What is the highest salary in Finance?”*"
      ],
      "metadata": {
        "id": "GmwIXCAk5SaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Average salary per department\n",
        "df.groupBy(\"department\").avg(\"salary\").show()\n",
        "\n",
        "# Maximum salary per department\n",
        "df.groupBy(\"department\").max(\"salary\").show()\n",
        "\n",
        "# Count employees per department\n",
        "df.groupBy(\"department\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us8vEYTly1ys",
        "outputId": "32283e5f-b36f-43ec-aeba-f8af866d4bd5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|department|avg(salary)|\n",
            "+----------+-----------+\n",
            "|        HR|    60000.0|\n",
            "|   Finance|    57500.0|\n",
            "| Marketing|    52000.0|\n",
            "|        IT|    65000.0|\n",
            "+----------+-----------+\n",
            "\n",
            "+----------+-----------+\n",
            "|department|max(salary)|\n",
            "+----------+-----------+\n",
            "|        HR|      60000|\n",
            "|   Finance|      67000|\n",
            "| Marketing|      52000|\n",
            "|        IT|      75000|\n",
            "+----------+-----------+\n",
            "\n",
            "+----------+-----+\n",
            "|department|count|\n",
            "+----------+-----+\n",
            "|        HR|    1|\n",
            "|   Finance|    2|\n",
            "| Marketing|    1|\n",
            "|        IT|    2|\n",
            "+----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"employees\")\n",
        "\n",
        "spark.sql(\"SELECT department, AVG(salary) AS avg_salary FROM employees GROUP BY department\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q33AnbSt5w4h",
        "outputId": "2fc5e45b-24f0-4525-dd1a-04e35d4a32ac"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|department|avg_salary|\n",
            "+----------+----------+\n",
            "|        HR|   60000.0|\n",
            "|   Finance|   57500.0|\n",
            "| Marketing|   52000.0|\n",
            "|        IT|   65000.0|\n",
            "+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sbeUaVvE9HNL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
